<!DOCTYPE html>
<head>
    <title>harsha</title>
    <meta charset="utf-8">
    <link rel="stylesheet" href="stylesheet.css">
    
</head>
<body>
  <section id="home"><h1 class="name">K.HARSHA VARDHAN REDDY</h1></section>
    <nav class="nav">
  <a class="h" href="#home">Home</a>
  <a href="#about">About</a>
  <a href="#skills">Skills</a>
  <a href="#projects">Projects</a>
  <a href="#contact">Contact</a>
</nav>
<section id="K" class="profile">
  <a href="file:///C:/Users/khars/Downloads/harshavardhan-resume.pdf%20(4).pdf" target="_blank">View Resume</a>
</section>
<section id="about">
  <h2>about me</h2>
  <p>Hello! I'm K. Harsha Vardhan Reddy, a recent BCA graduate from Mohan Babu University in Tirupati.
     I'm passionate about technology, coding, and learning new tools that can help solve real-world problems.</p><hr>
</section>
<section id="skills">
  <h2>Technical Skills</h2>
    <ul class="tech">
      <li>Programming Languages: Python, C, Java (basic)</li>
      <li>Web Technologies: HTML, CSS, JavaScript, Bootstrap</li>
      <li>Database: MySQL</li>
      <li>Operating Systems: Windows, Linux (basic)</li>
    </ul><hr>
</section>
<section  class ="project" id="projects">
  <h2>Projects</h2>
  <h3>collage project(detection of deepfake audios using deep learning techninques) </h3>
  <p>
    <ul>
    <li><strong>Description:</strong>
This project focuses on identifying and classifying deepfake audio clips using advanced deep learning models. With the increasing use of AI to synthesize human voices, deepfake audio poses serious risks to digital security, misinformation, and privacy. Our system is designed to detect such audio manipulations reliably.<br></li>
<strong>Key Highlights:</strong><li class="Goal">Goal: To develop an AI system capable of distinguishing between real and synthetically generated audio.</li>

<li class="Technologies">Technologies Used: Python, TensorFlow/Keras, Librosa (for audio feature extraction), CNN, RNN, and spectrogram analysis.</li>
<li class="meth">Methodology:Collected and pre-processed real and fake audio datasets.</li>
<li class="extract">Extracted Mel-frequency cepstral coefficients (MFCCs) and spectrograms from audio signals.
Trained convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to classify the audio files.
Evaluated model performance using accuracy, precision, recall, and F1 score.</li>
<strong>outcome:</strong>
<li class="outcome">Achieved a detection accuracy of around XX% (replace with your actual result), with strong generalization across unseen test data.<br></li>
Tools & Libraries:
Python, TensorFlow, Keras, Librosa, NumPy, Matplotlib, Jupyter Notebook
Challenges Overcome:
Handling imbalanced datasets (real vs fake).
Fine-tuning model parameters to improve classification accuracy.
Ensuring model robustness across different types of voices and background noise.</li>
  </ul></p><hr>
</section>
<br>
<br>
<br>
<section id="coursera">
  <h2>coursera</h2>
  <a href="c:\Users\khars\Pictures\Screenshots\interactive computer graphics.pdf">interactive computer graphics</a>
</section>
<br>
<br>
<br>
<br>
<section class="contact" id="contact">
  <footer>
        <p>Address:22-23, pacharla vandla palli,yarravari palem, tirupati,india</p>
        <p>Conatact: <a href="+91 7013266414" target="_self"> contact me</a></p>
        <p>Email: <a href="mailto:kharshavardhanreddy423@gmail.com">mail</a></p>
</footer>
</section>
</body>